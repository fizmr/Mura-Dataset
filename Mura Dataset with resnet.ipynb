{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown\n!pip install -q albumentations\n\n# --- 1. ADIM: VERİ SETİNİ KAGGLE ORTAMINA İNDİRME VE AÇMA ---\nimport os\n\n# İndirilecek dosyanın Google Drive ID'si ve hedef dosya adı\n# Link: https://drive.google.com/file/d/1bPtSXPnMYP5z3PUUVoZPk7NLfm8R_mzM/\nfile_id = \"1bPtSXPnMYP5z3PUUVoZPk7NLfm8R_mzM\"\nzip_dosya_yolu = \"MURA-v1.1.zip\"\nhedef_klasor = \"unziped_mura/\" # Dosyaların çıkarılacağı klasör\n\n# gdown ile dosyayı indiriyoruz\nprint(\"Veri seti indiriliyor...\")\n!gdown --id {file_id} -O {zip_dosya_yolu}\nprint(\"\\nİndirme tamamlandı.\")\n\n# Hedef klasörü hazırlama ve zip dosyasını açma\nprint(f\"\\n'{hedef_klasor}' hazırlanıyor...\")\n!rm -rf \"{hedef_klasor}\" # Eğer klasör varsa temizle\n!mkdir -p \"{hedef_klasor}\"\n!unzip -q -n \"{zip_dosya_yolu}\" -d \"{hedef_klasor}\" # -q (quiet) modu logları azaltır, -n (no overwrite)\nprint(\"\\nZip dosyasından çıkarma işlemi tamamlandı.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-28T08:33:36.513974Z","iopub.execute_input":"2025-07-28T08:33:36.514134Z","iopub.status.idle":"2025-07-28T08:35:00.673009Z","shell.execute_reply.started":"2025-07-28T08:33:36.514118Z","shell.execute_reply":"2025-07-28T08:35:00.672265Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.6.15)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\nVeri seti indiriliyor...\n/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1bPtSXPnMYP5z3PUUVoZPk7NLfm8R_mzM\nFrom (redirected): https://drive.google.com/uc?id=1bPtSXPnMYP5z3PUUVoZPk7NLfm8R_mzM&confirm=t&uuid=30aa529c-e09c-41f2-8d30-3db85f37a0dd\nTo: /kaggle/working/MURA-v1.1.zip\n100%|██████████████████████████████████████| 3.38G/3.38G [00:40<00:00, 83.7MB/s]\n\nİndirme tamamlandı.\n\n'unziped_mura/' hazırlanıyor...\n\nZip dosyasından çıkarma işlemi tamamlandı.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- 2. ADIM: VERİLERİ YÜKLEME VE HAZIRLAMA ---\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport datetime\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfrom sklearn.utils.class_weight import compute_class_weight\nimport albumentations as A\n\n\nmain_dir = hedef_klasor # Artık ana dizinimiz burası\ntrain_csv_path = os.path.join(main_dir, \"MURA-v1.1/train_image_paths.csv\")\nvalid_csv_path = os.path.join(main_dir, \"MURA-v1.1/valid_image_paths.csv\")\n\n# Veri çerçevelerini oluşturma\ntrain_df = pd.read_csv(train_csv_path, header=None, names=['image_path'])\ntrain_df['full_path'] = train_df['image_path'].apply(lambda path: os.path.join(main_dir, path))\ntrain_df['label'] = train_df['image_path'].apply(lambda path: 1 if 'positive' in path else 0)\ntrain_df['label'] = train_df['label'].astype(str)\n\nvalid_df = pd.read_csv(valid_csv_path, header=None, names=['image_path'])\nvalid_df['full_path'] = valid_df['image_path'].apply(lambda path: os.path.join(main_dir, path))\nvalid_df['label'] = valid_df['image_path'].apply(lambda path: 1 if 'positive' in path else 0)\nvalid_df['label'] = valid_df['label'].astype(str)\n\nprint(\"\\nEğitim Veri Seti Dağılımı:\\n\", train_df['label'].value_counts())\nprint(\"\\nDoğrulama Veri Seti Dağılımı:\\n\", valid_df['label'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T08:36:29.046553Z","iopub.execute_input":"2025-07-28T08:36:29.047365Z","iopub.status.idle":"2025-07-28T08:36:50.200295Z","shell.execute_reply.started":"2025-07-28T08:36:29.047326Z","shell.execute_reply":"2025-07-28T08:36:50.199638Z"}},"outputs":[{"name":"stderr","text":"2025-07-28 08:36:31.526647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753691791.775220      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753691791.843295      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\nEğitim Veri Seti Dağılımı:\n label\n0    21935\n1    14873\nName: count, dtype: int64\n\nDoğrulama Veri Seti Dağılımı:\n label\n0    1667\n1    1530\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"### --- ADIM 3: VERİLERİ HAZIRLAMA VE SINIF AĞIRLIKLARI (DÜZELTİLMİŞ) --- ###\n\nprint(\"\\n--- Veri Bilgileri Yükleniyor ve Hazırlanıyor ---\")\nmain_dir = hedef_klasor\ntrain_csv_path = os.path.join(main_dir, \"MURA-v1.1/train_image_paths.csv\")\nvalid_csv_path = os.path.join(main_dir, \"MURA-v1.1/valid_image_paths.csv\")\n\ntrain_df = pd.read_csv(train_csv_path, header=None, names=['image_path'])\ntrain_df['full_path'] = train_df['image_path'].apply(lambda path: os.path.join(main_dir, path))\ntrain_df['label'] = train_df['image_path'].apply(lambda path: 1 if 'positive' in path else 0)\n\nvalid_df = pd.read_csv(valid_csv_path, header=None, names=['image_path'])\nvalid_df['full_path'] = valid_df['image_path'].apply(lambda path: os.path.join(main_dir, path))\nvalid_df['label'] = valid_df['image_path'].apply(lambda path: 1 if 'positive' in path else 0)\n\n# Sınıf ağırlıklarını hesapla\nclass_weights = compute_class_weight('balanced', classes=np.unique(train_df['label']), y=train_df['label'])\nclass_weight_dict = dict(enumerate(class_weights))\nprint(f\"Hesaplanan Sınıf Ağırlıkları: {class_weight_dict}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T08:36:55.179718Z","iopub.execute_input":"2025-07-28T08:36:55.180511Z","iopub.status.idle":"2025-07-28T08:36:55.331800Z","shell.execute_reply.started":"2025-07-28T08:36:55.180485Z","shell.execute_reply":"2025-07-28T08:36:55.331040Z"}},"outputs":[{"name":"stdout","text":"\n--- Veri Bilgileri Yükleniyor ve Hazırlanıyor ---\nHesaplanan Sınıf Ağırlıkları: {0: 0.8390243902439024, 1: 1.2374100719424461}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(\"\\n--- Albumentations Pipeline'ları Oluşturuluyor ---\")\nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32\n\ndef get_train_augs():\n    \"\"\"Eğitim seti için kullanılacak 'hafifletilmiş' ve güvenli zenginleştirme adımları.\"\"\"\n    return A.Compose([\n        A.Resize(height=IMAGE_SIZE[0], width=IMAGE_SIZE[1]),\n        A.HorizontalFlip(p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.08, scale_limit=0.1, rotate_limit=10, p=0.7),\n        A.RandomBrightnessContrast(p=0.5),\n        A.Normalize()\n    ])\n\ndef get_valid_augs():\n    \"\"\"Doğrulama seti için sadece yeniden boyutlandırma ve normalizasyon.\"\"\"\n    return A.Compose([\n        A.Resize(height=IMAGE_SIZE[0], width=IMAGE_SIZE[1]),\n        A.Normalize()\n    ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T08:42:37.213552Z","iopub.execute_input":"2025-07-28T08:42:37.214054Z","iopub.status.idle":"2025-07-28T08:42:37.219388Z","shell.execute_reply.started":"2025-07-28T08:42:37.214030Z","shell.execute_reply":"2025-07-28T08:42:37.218692Z"}},"outputs":[{"name":"stdout","text":"\n--- Albumentations Pipeline'ları Oluşturuluyor ---\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class AlbumentationsDataGenerator(Sequence):\n    def __init__(self, dataframe, batch_size, augmentations, shuffle=False):\n        self.df, self.batch_size, self.augmentations, self.shuffle = dataframe, batch_size, augmentations, shuffle\n        self.image_paths, self.labels = self.df['full_path'].tolist(), self.df['label'].tolist()\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.ceil(len(self.image_paths) / self.batch_size))\n\n    def __getitem__(self, index):\n        batch_indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n        batch_images, batch_labels = [], []\n        for i in batch_indices:\n            img = cv2.imread(self.image_paths[i])\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            if self.augmentations:\n                img = self.augmentations(image=img)['image']\n            batch_images.append(img)\n            batch_labels.append(self.labels[i])\n        return np.array(batch_images), np.array(batch_labels)\n\n    def on_epoch_end(self):\n        self.indices = np.arange(len(self.image_paths))\n        if self.shuffle: np.random.shuffle(self.indices)\n\ntrain_generator = AlbumentationsDataGenerator(train_df, BATCH_SIZE, get_train_augs(), shuffle=True)\nvalidation_generator = AlbumentationsDataGenerator(valid_df, BATCH_SIZE, get_valid_augs(), shuffle=False)\nprint(\"Albumentations veri üreteçleri hazır.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T08:42:43.698412Z","iopub.execute_input":"2025-07-28T08:42:43.699077Z","iopub.status.idle":"2025-07-28T08:42:43.717109Z","shell.execute_reply.started":"2025-07-28T08:42:43.699052Z","shell.execute_reply":"2025-07-28T08:42:43.716495Z"}},"outputs":[{"name":"stdout","text":"Albumentations veri üreteçleri hazır.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(\"\\n--- ResNet50V2 Modeli Oluşturuluyor ---\")\nbase_model = ResNet50V2(input_shape=(*IMAGE_SIZE, 3), include_top=False, weights='imagenet')\nbase_model.trainable = False\n\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T08:42:47.380422Z","iopub.execute_input":"2025-07-28T08:42:47.380711Z","iopub.status.idle":"2025-07-28T08:42:53.437220Z","shell.execute_reply.started":"2025-07-28T08:42:47.380690Z","shell.execute_reply":"2025-07-28T08:42:53.436407Z"}},"outputs":[{"name":"stdout","text":"\n--- ResNet50V2 Modeli Oluşturuluyor ---\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1753692167.623125      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(\"\\n--- İlk Aşama Eğitimi Başlıyor ---\")\nINITIAL_EPOCHS = 25 # Bu aşama için epoch sayısını biraz artırabiliriz\nmodel.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\ncheckpoint_phase1 = ModelCheckpoint('best_model_phase1.h5', monitor='val_loss', mode='min', save_best_only=True, verbose=1)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\nhistory_phase1 = model.fit(\n    train_generator,\n    epochs=INITIAL_EPOCHS,\n    validation_data=validation_generator,\n    class_weight=class_weight_dict,\n    callbacks=[checkpoint_phase1, early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T08:46:51.374570Z","iopub.execute_input":"2025-07-28T08:46:51.375332Z"}},"outputs":[{"name":"stdout","text":"\n--- İlk Aşama Eğitimi Başlıyor ---\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1753692420.984371     115 service.cc:148] XLA service 0x7d6aa0291a80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1753692420.985759     115 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1753692422.410760     115 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   1/1151\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:02:24\u001b[0m 16s/step - accuracy: 0.5312 - loss: 2.2946","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1753692427.692200     115 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.5356 - loss: 1.2998\nEpoch 1: val_loss improved from inf to 0.75108, saving model to best_model_phase1.h5\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 191ms/step - accuracy: 0.5356 - loss: 1.2994 - val_accuracy: 0.5912 - val_loss: 0.7511\nEpoch 2/25\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.5533 - loss: 0.7487\nEpoch 2: val_loss improved from 0.75108 to 0.70952, saving model to best_model_phase1.h5\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 179ms/step - accuracy: 0.5533 - loss: 0.7487 - val_accuracy: 0.5812 - val_loss: 0.7095\nEpoch 3/25\n\u001b[1m1102/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 171ms/step - accuracy: 0.5694 - loss: 0.7196","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- İnce Ayar (Fine-Tuning) Aşaması Başlıyor ---\")\nmodel = load_model('best_model_phase1.h5') # İlk aşamanın en iyi modelini yükle\nbase_model = model.layers[0]\nbase_model.trainable = True\n\nfine_tune_at = 140\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n\nFINE_TUNE_EPOCHS = 40 # İnce ayar için daha fazla epoch\ndecay_steps = len(train_generator) * FINE_TUNE_EPOCHS\ncosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(1e-5, decay_steps, alpha=1e-7)\n\nmodel.compile(optimizer=Adam(learning_rate=cosine_decay_scheduler), loss='binary_crossentropy', metrics=['accuracy'])\ncheckpoint_finetune = ModelCheckpoint('best_model_finetuned.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)\n\nhistory_finetune = model.fit(\n    train_generator,\n    epochs=FINE_TUNE_EPOCHS,\n    validation_data=validation_generator,\n    class_weight=class_weight_dict,\n    callbacks=[checkpoint_finetune]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T13:11:29.173430Z","iopub.execute_input":"2025-07-26T13:11:29.173708Z","iopub.status.idle":"2025-07-26T13:11:29.198356Z","shell.execute_reply.started":"2025-07-26T13:11:29.173687Z","shell.execute_reply":"2025-07-26T13:11:29.197744Z"}},"outputs":[{"name":"stdout","text":"\n--- İnce Ayar (Fine-Tuning) Aşaması Başlıyor ---\n\n--- Model Özeti (İnce Ayar Aşaması) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,614,401\u001b[0m (93.90 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,614,401</span> (93.90 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,401,857\u001b[0m (66.38 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,401,857</span> (66.38 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,212,544\u001b[0m (27.51 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,212,544</span> (27.51 MB)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"print(\"\\n--- Nihai Model Değerlendiriliyor ---\")\nmodel = load_model('best_model_finetuned.h5') # Tüm sürecin en iyi modelini yükle\nscores = model.evaluate(validation_generator)\nprint(\"-\" * 50)\nprint(f\"NİHAİ DOĞRULUK: {scores[1] * 100:.2f}%\")\nprint(f\"NİHAİ KAYIP: {scores[0]}\")\nprint(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-26T13:11:32.043164Z","iopub.execute_input":"2025-07-26T13:11:32.043440Z"}},"outputs":[{"name":"stdout","text":"\nModel 30 epoch daha (ince ayar) eğitiliyor...\nEpoch 21/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 270ms/step - accuracy: 0.5656 - loss: 0.6963 - val_accuracy: 0.6212 - val_loss: 0.6429 - learning_rate: 1.0000e-05\nEpoch 22/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 261ms/step - accuracy: 0.6305 - loss: 0.6573 - val_accuracy: 0.6606 - val_loss: 0.6152 - learning_rate: 1.0000e-05\nEpoch 23/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 270ms/step - accuracy: 0.6535 - loss: 0.6374 - val_accuracy: 0.6775 - val_loss: 0.5901 - learning_rate: 1.0000e-05\nEpoch 24/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 257ms/step - accuracy: 0.6764 - loss: 0.6158 - val_accuracy: 0.6991 - val_loss: 0.5755 - learning_rate: 1.0000e-05\nEpoch 25/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 251ms/step - accuracy: 0.6851 - loss: 0.6030 - val_accuracy: 0.7079 - val_loss: 0.5672 - learning_rate: 1.0000e-05\nEpoch 26/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 254ms/step - accuracy: 0.7010 - loss: 0.5928 - val_accuracy: 0.7041 - val_loss: 0.5499 - learning_rate: 1.0000e-05\nEpoch 27/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 266ms/step - accuracy: 0.7000 - loss: 0.5912 - val_accuracy: 0.7079 - val_loss: 0.5412 - learning_rate: 1.0000e-05\nEpoch 28/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 262ms/step - accuracy: 0.7001 - loss: 0.5833 - val_accuracy: 0.7194 - val_loss: 0.5394 - learning_rate: 1.0000e-05\nEpoch 29/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 262ms/step - accuracy: 0.7102 - loss: 0.5766 - val_accuracy: 0.7326 - val_loss: 0.5281 - learning_rate: 1.0000e-05\nEpoch 30/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 256ms/step - accuracy: 0.7118 - loss: 0.5743 - val_accuracy: 0.7373 - val_loss: 0.5238 - learning_rate: 1.0000e-05\nEpoch 31/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 257ms/step - accuracy: 0.7163 - loss: 0.5665 - val_accuracy: 0.7476 - val_loss: 0.5211 - learning_rate: 1.0000e-05\nEpoch 32/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 254ms/step - accuracy: 0.7166 - loss: 0.5662 - val_accuracy: 0.7391 - val_loss: 0.5228 - learning_rate: 1.0000e-05\nEpoch 33/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 256ms/step - accuracy: 0.7228 - loss: 0.5615 - val_accuracy: 0.7438 - val_loss: 0.5235 - learning_rate: 1.0000e-05\nEpoch 34/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 260ms/step - accuracy: 0.7246 - loss: 0.5577 - val_accuracy: 0.7423 - val_loss: 0.5146 - learning_rate: 1.0000e-05\nEpoch 35/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 261ms/step - accuracy: 0.7272 - loss: 0.5545 - val_accuracy: 0.7510 - val_loss: 0.4988 - learning_rate: 1.0000e-05\nEpoch 36/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 259ms/step - accuracy: 0.7327 - loss: 0.5426 - val_accuracy: 0.7548 - val_loss: 0.4990 - learning_rate: 1.0000e-05\nEpoch 37/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 261ms/step - accuracy: 0.7301 - loss: 0.5426 - val_accuracy: 0.7423 - val_loss: 0.5141 - learning_rate: 1.0000e-05\nEpoch 38/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 258ms/step - accuracy: 0.7322 - loss: 0.5464 - val_accuracy: 0.7632 - val_loss: 0.4938 - learning_rate: 1.0000e-05\nEpoch 39/50\n\u001b[1m1151/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 258ms/step - accuracy: 0.7373 - loss: 0.5385 - val_accuracy: 0.7654 - val_loss: 0.4938 - learning_rate: 1.0000e-05\nEpoch 40/50\n\u001b[1m 998/1151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m37s\u001b[0m 244ms/step - accuracy: 0.7400 - loss: 0.5399","output_type":"stream"}],"execution_count":null}]}
